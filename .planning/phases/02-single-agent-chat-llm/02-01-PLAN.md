---
phase: 02-single-agent-chat-llm
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/boternity-types/src/llm.rs
  - crates/boternity-types/src/chat.rs
  - crates/boternity-types/src/agent.rs
  - crates/boternity-types/src/memory.rs
  - crates/boternity-types/src/lib.rs
  - crates/boternity-core/src/llm/mod.rs
  - crates/boternity-core/src/llm/provider.rs
  - crates/boternity-core/src/llm/types.rs
  - crates/boternity-core/src/llm/token_budget.rs
  - crates/boternity-core/src/llm/box_provider.rs
  - crates/boternity-core/src/chat/mod.rs
  - crates/boternity-core/src/chat/repository.rs
  - crates/boternity-core/src/memory/mod.rs
  - crates/boternity-core/src/memory/store.rs
  - crates/boternity-core/src/lib.rs
autonomous: true

must_haves:
  truths:
    - "LlmProvider trait defines complete/stream/count_tokens methods with RPITIT"
    - "BoxLlmProvider enables runtime provider selection via dynamic dispatch"
    - "ChatRepository trait defines session and message CRUD with RPITIT"
    - "MemoryRepository trait defines memory storage and retrieval with RPITIT"
    - "Domain types cover all data shapes needed for chat, LLM, and memory"
  artifacts:
    - path: "crates/boternity-types/src/llm.rs"
      provides: "CompletionRequest, CompletionResponse, StreamEvent, StreamChunk, Usage, StopReason, TokenCount, MessageRole for LLM"
      contains: "StreamEvent"
    - path: "crates/boternity-types/src/chat.rs"
      provides: "ChatSession, ChatMessage, SessionStatus, MessageRole, ContextSummary"
      contains: "ChatSession"
    - path: "crates/boternity-types/src/memory.rs"
      provides: "MemoryEntry, MemoryCategory, PendingExtraction"
      contains: "MemoryEntry"
    - path: "crates/boternity-types/src/agent.rs"
      provides: "AgentConfig for agent identity"
      contains: "AgentConfig"
    - path: "crates/boternity-core/src/llm/provider.rs"
      provides: "LlmProvider trait with RPITIT async methods"
      contains: "trait LlmProvider"
    - path: "crates/boternity-core/src/llm/box_provider.rs"
      provides: "BoxLlmProvider for dynamic dispatch"
      contains: "BoxLlmProvider"
    - path: "crates/boternity-core/src/chat/repository.rs"
      provides: "ChatRepository trait"
      contains: "trait ChatRepository"
    - path: "crates/boternity-core/src/memory/store.rs"
      provides: "MemoryRepository trait"
      contains: "trait MemoryRepository"
  key_links:
    - from: "crates/boternity-core/src/llm/provider.rs"
      to: "crates/boternity-types/src/llm.rs"
      via: "imports CompletionRequest, CompletionResponse, StreamEvent"
      pattern: "use boternity_types::llm::"
    - from: "crates/boternity-core/src/llm/box_provider.rs"
      to: "crates/boternity-core/src/llm/provider.rs"
      via: "blanket impl LlmProviderDyn for T: LlmProvider"
      pattern: "impl.*LlmProviderDyn.*for T"
    - from: "crates/boternity-core/src/chat/repository.rs"
      to: "crates/boternity-types/src/chat.rs"
      via: "imports ChatSession, ChatMessage, ContextSummary"
      pattern: "use boternity_types::chat::"
---

<objective>
Define all Phase 2 domain types and trait abstractions for LLM providers, chat sessions, memory, and agents.

Purpose: Every other Phase 2 plan depends on these types and traits. This plan establishes the vocabulary and contracts that the Anthropic provider, SQLite persistence, agent engine, and CLI all program against. Following Phase 1's pattern: types in boternity-types, traits in boternity-core.

Output: New type modules (llm, chat, agent, memory) in boternity-types, new trait modules (llm/, chat/, memory/) in boternity-core with LlmProvider, BoxLlmProvider, ChatRepository, and MemoryRepository.
</objective>

<execution_context>
@/Users/smxaz7/.claude/get-shit-done/workflows/execute-plan.md
@/Users/smxaz7/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-single-agent-chat-llm/02-RESEARCH.md
@.planning/phases/02-single-agent-chat-llm/02-CONTEXT.md
@crates/boternity-types/src/lib.rs
@crates/boternity-types/src/bot.rs
@crates/boternity-core/src/lib.rs
@crates/boternity-core/src/repository/bot.rs
@crates/boternity-core/src/repository/secret.rs
@crates/boternity-core/src/service/secret.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Phase 2 domain types in boternity-types</name>
  <files>
    crates/boternity-types/src/llm.rs
    crates/boternity-types/src/chat.rs
    crates/boternity-types/src/agent.rs
    crates/boternity-types/src/memory.rs
    crates/boternity-types/src/lib.rs
  </files>
  <action>
Create four new type modules in boternity-types. Follow existing patterns from bot.rs (Serialize/Deserialize derives, UUIDv7 IDs, Display/FromStr impls, chrono timestamps).

**llm.rs** -- LLM request/response types:
- `MessageRole` enum: System, User, Assistant (with serde rename_all = "lowercase", Display, FromStr)
- `Message` struct: role (MessageRole), content (String)
- `CompletionRequest` struct: model (String), messages (Vec<Message>), system (Option<String>), max_tokens (u32), temperature (Option<f64>), stream (bool), stop_sequences (Option<Vec<String>>)
- `CompletionResponse` struct: id (String), content (String), model (String), stop_reason (StopReason), usage (Usage)
- `StopReason` enum: EndTurn, ToolUse, MaxTokens, StopSequence, PauseTurn (with serde rename_all = "snake_case", Display, FromStr)
- `Usage` struct (Default derive): input_tokens (u32), output_tokens (u32), cache_creation_input_tokens (Option<u32>), cache_read_input_tokens (Option<u32>)
- `TokenCount` struct: input_tokens (u32)
- `StreamEvent` enum: Connected, ContentBlockStart { index: u32, content_type: String }, TextDelta { index: u32, text: String }, ThinkingDelta { index: u32, thinking: String }, ToolUseComplete { id: String, name: String, input: serde_json::Value }, ContentBlockStop { index: u32 }, MessageDelta { stop_reason: StopReason }, Usage(Usage), Done
- `LlmError` enum (thiserror): Provider { message: String }, Deserialization(String), Stream(String), RateLimited { retry_after_ms: Option<u64> }, Overloaded(String), AuthenticationFailed, ContextLengthExceeded { max: u32, requested: u32 }, InvalidRequest(String)
- `ProviderCapabilities` struct: streaming (bool), tool_calling (bool), vision (bool), extended_thinking (bool), max_context_tokens (u32), max_output_tokens (u32)

**chat.rs** -- Chat session, message, and context summary types:
- `SessionStatus` enum: Active, Completed, Crashed (with serde rename_all = "lowercase", Display, FromStr, CHECK constraint matching SQL schema)
- `ChatSession` struct: id (Uuid), bot_id (Uuid), title (Option<String>), started_at (DateTime<Utc>), ended_at (Option<DateTime<Utc>>), total_input_tokens (u32), total_output_tokens (u32), message_count (u32), model (String), status (SessionStatus)
- `ChatMessage` struct: id (Uuid), session_id (Uuid), role (MessageRole -- re-export from llm), content (String), created_at (DateTime<Utc>), input_tokens (Option<u32>), output_tokens (Option<u32>), model (Option<String>), stop_reason (Option<String>), response_ms (Option<u64>)
- `ContextSummary` struct: id (Uuid), session_id (Uuid), summary (String), messages_start (u32), messages_end (u32), token_count (u32), created_at (DateTime<Utc>). This is the definitive location for this type -- it belongs in chat.rs because context summaries are scoped to chat sessions, not memory.
- Re-export `MessageRole` from llm module (it's used in both chat and llm contexts)

**agent.rs** -- Agent configuration:
- `AgentConfig` struct: bot_id (Uuid), bot_name (String), bot_slug (String), bot_emoji (Option<String>), model (String), temperature (f64), max_tokens (u32)

**memory.rs** -- Memory types:
- `MemoryCategory` enum: Preference, Fact, Decision, Context, Correction (with serde rename_all = "lowercase", Display, FromStr)
- `MemoryEntry` struct: id (Uuid), bot_id (Uuid), session_id (Uuid), fact (String), category (MemoryCategory), importance (u8 -- 1 to 5), source_message_id (Option<Uuid>), superseded_by (Option<Uuid>), created_at (DateTime<Utc>), is_manual (bool)
- `PendingExtraction` struct: id (Uuid), session_id (Uuid), bot_id (Uuid), attempt_count (u32), last_attempt_at (Option<DateTime<Utc>>), next_attempt_at (DateTime<Utc>), error_message (Option<String>), created_at (DateTime<Utc>)

Update `lib.rs` to add `pub mod llm; pub mod chat; pub mod agent; pub mod memory;`
  </action>
  <verify>
Run `cargo check -p boternity-types` -- all new types compile without errors.
  </verify>
  <done>All Phase 2 domain types exist in boternity-types with proper derives (Serialize, Deserialize, Debug, Clone), Display/FromStr for enums, and UUIDv7 ID patterns matching existing bot.rs conventions. ContextSummary is defined in chat.rs.</done>
</task>

<task type="auto">
  <name>Task 2: Create LlmProvider trait, BoxLlmProvider, and TokenBudget in boternity-core</name>
  <files>
    crates/boternity-core/src/llm/mod.rs
    crates/boternity-core/src/llm/provider.rs
    crates/boternity-core/src/llm/types.rs
    crates/boternity-core/src/llm/token_budget.rs
    crates/boternity-core/src/llm/box_provider.rs
    crates/boternity-core/src/lib.rs
    crates/boternity-core/Cargo.toml
  </files>
  <action>
Create the LlmProvider trait following the RPITIT + BoxProvider pattern documented in RESEARCH.md (Pattern 1). This is the core abstraction that all LLM providers implement.

**provider.rs** -- LlmProvider trait:
- `trait LlmProvider: Send + Sync` with methods:
  - `fn name(&self) -> &str` -- provider identifier
  - `fn capabilities(&self) -> &ProviderCapabilities` -- what this provider supports
  - `fn complete(&self, request: &CompletionRequest) -> impl Future<Output = Result<CompletionResponse, LlmError>> + Send` -- RPITIT
  - `fn stream(&self, request: CompletionRequest) -> Pin<Box<dyn Stream<Item = Result<StreamEvent, LlmError>> + Send + 'static>>` -- boxed stream (not RPITIT because streams need to be object-safe)
  - `fn count_tokens(&self, request: &CompletionRequest) -> impl Future<Output = Result<TokenCount, LlmError>> + Send` -- RPITIT
- Import `futures_util::Stream` and `std::pin::Pin` for the stream return type

**box_provider.rs** -- BoxLlmProvider (following BoxSecretProvider pattern from 01-04):
- `trait LlmProviderDyn: Send + Sync` -- object-safe version with all async methods returning `Pin<Box<dyn Future + Send + '_>>`
- `impl<T: LlmProvider> LlmProviderDyn for T` -- blanket impl that boxes the RPITIT futures
- `struct BoxLlmProvider { inner: Box<dyn LlmProviderDyn + Send + Sync> }`
- `impl BoxLlmProvider { pub fn new<T: LlmProvider + 'static>(provider: T) -> Self }`
- Implement delegate methods on BoxLlmProvider: `name()`, `capabilities()`, `complete()`, `stream()`, `count_tokens()`
- Also make BoxLlmProvider implement LlmProvider trait itself if possible (so it can be used wherever LlmProvider is expected), OR provide equivalent methods directly. Since LlmProvider uses RPITIT, BoxLlmProvider cannot implement it directly -- instead provide the same method signatures returning concrete async blocks.

**token_budget.rs** -- Token budget management:
- `struct TokenBudget` with fields: max_context_tokens (u32), soul_budget (u32), memory_budget (u32), user_context_budget (u32), conversation_budget (u32)
- `impl TokenBudget`:
  - `fn new(max_context: u32) -> Self` -- allocate: soul 15%, memory 10%, user_context 5%, conversation 70%
  - `fn conversation_remaining(&self, used: u32) -> u32`
  - `fn should_summarize(&self, conversation_tokens: u32) -> bool` -- true when conversation tokens > 80% of conversation_budget
  - `fn from_capabilities(caps: &ProviderCapabilities) -> Self` -- derive from provider caps

**types.rs** -- Re-exports from boternity-types for convenience:
- `pub use boternity_types::llm::*;`

**mod.rs** -- Module re-exports:
- `pub mod provider; pub mod box_provider; pub mod token_budget; pub mod types;`

Add `futures-util = { workspace = true }` to boternity-core/Cargo.toml dependencies. Add `futures-util = "0.3"` to workspace Cargo.toml if not already there.

Update `crates/boternity-core/src/lib.rs` to add `pub mod llm;`
  </action>
  <verify>
Run `cargo check -p boternity-core` -- LlmProvider trait, BoxLlmProvider, and TokenBudget compile. Verify BoxLlmProvider follows the same blanket-impl pattern as BoxSecretProvider by checking the impl block structure.
  </verify>
  <done>LlmProvider trait is defined with RPITIT async methods and Pin<Box<dyn Stream>> for streaming. BoxLlmProvider provides object-safe dynamic dispatch following the established BoxSecretProvider pattern. TokenBudget allocates context window budgets with soul/memory/conversation priorities.</done>
</task>

<task type="auto">
  <name>Task 3: Create ChatRepository and MemoryRepository traits in boternity-core</name>
  <files>
    crates/boternity-core/src/chat/mod.rs
    crates/boternity-core/src/chat/repository.rs
    crates/boternity-core/src/memory/mod.rs
    crates/boternity-core/src/memory/store.rs
    crates/boternity-core/src/lib.rs
  </files>
  <action>
Create repository traits following the exact same pattern as BotRepository in boternity-core/src/repository/bot.rs (RPITIT, Send + Sync, RepositoryError).

**chat/repository.rs** -- ChatRepository trait:
- `trait ChatRepository: Send + Sync` with methods:
  - `fn create_session(&self, session: &ChatSession) -> impl Future<Output = Result<ChatSession, RepositoryError>> + Send`
  - `fn get_session(&self, session_id: &Uuid) -> impl Future<Output = Result<Option<ChatSession>, RepositoryError>> + Send`
  - `fn update_session(&self, session: &ChatSession) -> impl Future<Output = Result<(), RepositoryError>> + Send`
  - `fn list_sessions(&self, bot_id: &Uuid, limit: Option<i64>, offset: Option<i64>) -> impl Future<Output = Result<Vec<ChatSession>, RepositoryError>> + Send`
  - `fn delete_session(&self, session_id: &Uuid) -> impl Future<Output = Result<(), RepositoryError>> + Send`
  - `fn get_active_sessions(&self, bot_id: &Uuid) -> impl Future<Output = Result<Vec<ChatSession>, RepositoryError>> + Send`
  - `fn save_message(&self, message: &ChatMessage) -> impl Future<Output = Result<(), RepositoryError>> + Send`
  - `fn get_messages(&self, session_id: &Uuid, limit: Option<i64>, offset: Option<i64>) -> impl Future<Output = Result<Vec<ChatMessage>, RepositoryError>> + Send`
  - `fn get_message_count(&self, session_id: &Uuid) -> impl Future<Output = Result<u32, RepositoryError>> + Send`
  - `fn save_context_summary(&self, summary: &ContextSummary) -> impl Future<Output = Result<(), RepositoryError>> + Send`
  - `fn get_latest_summary(&self, session_id: &Uuid) -> impl Future<Output = Result<Option<ContextSummary>, RepositoryError>> + Send`

Note: `save_context_summary` and `get_latest_summary` belong on ChatRepository (not MemoryRepository) because context summaries are session-scoped. Import `ContextSummary` from `boternity_types::chat::ContextSummary` (defined in Plan 01 Task 1).

**memory/store.rs** -- MemoryRepository trait:
- `trait MemoryRepository: Send + Sync` with methods:
  - `fn save_memory(&self, entry: &MemoryEntry) -> impl Future<Output = Result<(), RepositoryError>> + Send`
  - `fn get_memories(&self, bot_id: &Uuid, limit: Option<i64>) -> impl Future<Output = Result<Vec<MemoryEntry>, RepositoryError>> + Send` -- ordered by importance DESC, created_at DESC
  - `fn delete_memory(&self, memory_id: &Uuid) -> impl Future<Output = Result<(), RepositoryError>> + Send`
  - `fn delete_all_memories(&self, bot_id: &Uuid) -> impl Future<Output = Result<u64, RepositoryError>> + Send` -- returns count deleted
  - `fn get_memories_by_session(&self, session_id: &Uuid) -> impl Future<Output = Result<Vec<MemoryEntry>, RepositoryError>> + Send`
  - `fn save_pending_extraction(&self, pending: &PendingExtraction) -> impl Future<Output = Result<(), RepositoryError>> + Send`
  - `fn get_pending_extractions(&self, bot_id: &Uuid) -> impl Future<Output = Result<Vec<PendingExtraction>, RepositoryError>> + Send`
  - `fn delete_pending_extraction(&self, id: &Uuid) -> impl Future<Output = Result<(), RepositoryError>> + Send`
  - `fn update_pending_extraction(&self, pending: &PendingExtraction) -> impl Future<Output = Result<(), RepositoryError>> + Send`

**mod.rs** files: Re-export trait and types.

Update `crates/boternity-core/src/lib.rs` to add `pub mod chat; pub mod memory;` (in addition to `pub mod llm` from Task 2).
  </action>
  <verify>
Run `cargo check -p boternity-core` -- all traits compile. Run `cargo check --workspace` to verify no dependency violations (core must not depend on infra).
  </verify>
  <done>ChatRepository and MemoryRepository traits exist in boternity-core with full CRUD methods using RPITIT pattern. ChatRepository includes save_context_summary and get_latest_summary for sliding window management. The workspace compiles cleanly with zero core->infra dependencies.</done>
</task>

</tasks>

<verification>
1. `cargo check --workspace` passes with no errors
2. boternity-types has new modules: llm, chat, agent, memory
3. boternity-core has new modules: llm (with provider, box_provider, token_budget, types), chat (with repository), memory (with store)
4. LlmProvider trait uses RPITIT for complete/count_tokens and Pin<Box<dyn Stream>> for stream
5. BoxLlmProvider follows the same blanket-impl pattern as BoxSecretProvider
6. ChatRepository and MemoryRepository follow the same RPITIT pattern as BotRepository
7. No dependency from boternity-core to boternity-infra
</verification>

<success_criteria>
- All Phase 2 domain types compile in boternity-types
- LlmProvider trait is defined with RPITIT + BoxLlmProvider for dynamic dispatch
- ChatRepository and MemoryRepository traits are defined with RPITIT
- ContextSummary type is defined in boternity-types/src/chat.rs
- TokenBudget provides context window allocation
- `cargo check --workspace` passes
- No circular or forbidden crate dependencies
</success_criteria>

<output>
After completion, create `.planning/phases/02-single-agent-chat-llm/02-01-SUMMARY.md`
</output>
