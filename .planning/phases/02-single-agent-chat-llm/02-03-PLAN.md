---
phase: 02-single-agent-chat-llm
plan: 03
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - crates/boternity-infra/src/llm/mod.rs
  - crates/boternity-infra/src/llm/anthropic/mod.rs
  - crates/boternity-infra/src/llm/anthropic/client.rs
  - crates/boternity-infra/src/llm/anthropic/streaming.rs
  - crates/boternity-infra/src/llm/anthropic/types.rs
  - crates/boternity-infra/src/lib.rs
  - crates/boternity-infra/Cargo.toml
autonomous: true
user_setup:
  - service: anthropic
    why: "LLM provider for bot conversations"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "console.anthropic.com -> API Keys -> Create Key (or use existing)"

must_haves:
  truths:
    - "AnthropicProvider implements LlmProvider trait for non-streaming completions"
    - "AnthropicProvider streams SSE events from the Anthropic Messages API and yields StreamEvent variants"
    - "SSE state machine correctly handles text_delta, content_block_start/stop, message_start/delta/stop, ping, and error events"
    - "Tool use input JSON fragments are accumulated per content block index and parsed on block stop"
    - "API key is wrapped in secrecy::SecretString and never appears in logs"
  artifacts:
    - path: "crates/boternity-infra/src/llm/anthropic/client.rs"
      provides: "AnthropicProvider implementing LlmProvider"
      contains: "impl LlmProvider for AnthropicProvider"
    - path: "crates/boternity-infra/src/llm/anthropic/streaming.rs"
      provides: "SSE stream creation and state machine"
      contains: "create_anthropic_stream"
    - path: "crates/boternity-infra/src/llm/anthropic/types.rs"
      provides: "Anthropic-specific request/response types"
      contains: "AnthropicRequest"
  key_links:
    - from: "crates/boternity-infra/src/llm/anthropic/client.rs"
      to: "crates/boternity-core/src/llm/provider.rs"
      via: "implements LlmProvider trait"
      pattern: "impl LlmProvider for AnthropicProvider"
    - from: "crates/boternity-infra/src/llm/anthropic/streaming.rs"
      to: "crates/boternity-types/src/llm.rs"
      via: "yields StreamEvent variants"
      pattern: "StreamEvent::"
    - from: "crates/boternity-infra/src/llm/anthropic/client.rs"
      to: "crates/boternity-infra/src/llm/anthropic/streaming.rs"
      via: "stream() delegates to create_anthropic_stream"
      pattern: "create_anthropic_stream"
---

<objective>
Implement the Anthropic Claude provider with full SSE streaming support.

Purpose: This is the concrete LLM integration that powers all bot conversations. It translates the generic LlmProvider interface into Anthropic Messages API calls, handling streaming SSE events through a state machine that correctly accumulates tool use JSON fragments and maps Anthropic-specific event types to the unified StreamEvent enum.

Output: AnthropicProvider in boternity-infra implementing LlmProvider trait, with reqwest+reqwest-eventsource HTTP client and SSE stream parser.
</objective>

<execution_context>
@/Users/smxaz7/.claude/get-shit-done/workflows/execute-plan.md
@/Users/smxaz7/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/02-single-agent-chat-llm/02-RESEARCH.md
@.planning/phases/02-single-agent-chat-llm/02-CONTEXT.md
@.planning/phases/02-single-agent-chat-llm/02-01-SUMMARY.md
@crates/boternity-infra/src/lib.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Anthropic-specific types and HTTP client</name>
  <files>
    crates/boternity-infra/src/llm/mod.rs
    crates/boternity-infra/src/llm/anthropic/mod.rs
    crates/boternity-infra/src/llm/anthropic/types.rs
    crates/boternity-infra/src/llm/anthropic/client.rs
    crates/boternity-infra/src/lib.rs
    crates/boternity-infra/Cargo.toml
  </files>
  <action>
Add Phase 2 deps to boternity-infra/Cargo.toml:
```toml
reqwest = { workspace = true }
reqwest-eventsource = { workspace = true }
async-stream = { workspace = true }
futures-util = { workspace = true }
secrecy = { workspace = true }
pin-project-lite = { workspace = true }
boternity-core = { workspace = true }
```
Ensure `boternity-types` and `serde_json` are also present (likely already are).

**types.rs** -- Anthropic Messages API types (these are Anthropic-specific, NOT the generic LLM types):
- `AnthropicRequest` struct (Serialize): model, max_tokens, messages (Vec<AnthropicMessage>), system (Option<String>), stream (bool), temperature (Option<f64>), stop_sequences (Option<Vec<String>>)
- `AnthropicMessage` struct (Serialize): role (String), content (String)
- `AnthropicSseEvent` enum (Deserialize, tagged by "type" field): MessageStart { message: AnthropicMessageObj }, ContentBlockStart { index: u32, content_block: AnthropicContentBlock }, ContentBlockDelta { index: u32, delta: AnthropicDelta }, ContentBlockStop { index: u32 }, MessageDelta { delta: AnthropicMessageDeltaObj, usage: AnthropicUsage }, MessageStop, Ping, Error { error: AnthropicError }
- `AnthropicMessageObj` (Deserialize): id, model, usage (Option<AnthropicUsage>)
- `AnthropicContentBlock` enum (Deserialize, tagged by "type"): Text { text: String }, ToolUse { id: String, name: String, input: serde_json::Value }
- `AnthropicDelta` enum (Deserialize, tagged by "type"): TextDelta { text: String }, ThinkingDelta { thinking: String }, InputJsonDelta { partial_json: String }, SignatureDelta { signature: String }
- `AnthropicUsage` (Deserialize, Default): input_tokens (u32), output_tokens (u32), cache_creation_input_tokens (Option<u32>), cache_read_input_tokens (Option<u32>)
- `AnthropicError` (Deserialize): error_type (String renamed from "type"), message (String)
- `AnthropicNonStreamResponse` (Deserialize): id, content (Vec<AnthropicContentBlock>), model, stop_reason (Option<String>), usage (AnthropicUsage)

Use `#[serde(tag = "type")]` for enum variants. Use `#[serde(rename = "...")]` where Anthropic field names differ from Rust conventions. The `AnthropicDelta` variants use: "text_delta", "thinking_delta", "input_json_delta", "signature_delta". The `AnthropicContentBlock` variants use: "text", "tool_use". Handle `AnthropicSseEvent` deserialization carefully: the SSE `event:` field names the variant (message_start, content_block_start, etc.), and the `data:` field contains the JSON payload. The reqwest-eventsource Message has both `.event` (the event type) and `.data` (the JSON). You need to match on `msg.event.as_str()` first, then deserialize `msg.data` into the appropriate payload struct. Do NOT use serde tag on the outer enum -- instead, use a match on event type string and deserialize the data into specific structs.

**client.rs** -- AnthropicProvider:
- `struct AnthropicProvider` with fields: client (reqwest::Client), api_key (secrecy::SecretString), base_url (String -- default "https://api.anthropic.com"), model (String), capabilities (ProviderCapabilities)
- Constructor: `pub fn new(api_key: secrecy::SecretString, model: String) -> Self`
  - Default base_url to "https://api.anthropic.com"
  - Create reqwest::Client with default timeout
  - Set capabilities based on model: claude-sonnet-4-20250514 -> max_context 200k, max_output 8192, streaming true, tool_calling true, vision true, extended_thinking false (sonnet default)
- `impl LlmProvider for AnthropicProvider`:
  - `fn name(&self) -> &str` -> "anthropic"
  - `fn capabilities(&self)` -> return stored capabilities
  - `fn complete(&self, request)` -> Convert CompletionRequest to AnthropicRequest (set stream: false), POST to /v1/messages, deserialize AnthropicNonStreamResponse, convert to CompletionResponse. Add headers: x-api-key, anthropic-version "2023-06-01", content-type application/json. Use `secrecy::ExposeSecret` to access the key ONLY for the header -- never log it.
  - `fn stream(&self, request)` -> delegate to streaming::create_anthropic_stream()
  - `fn count_tokens(&self, request)` -> For now, implement a simple estimation: 4 chars ~= 1 token. TODO comment noting the Anthropic /v1/messages/count_tokens API endpoint for exact counts in future.

Update lib.rs to add `pub mod llm;`
  </action>
  <verify>
Run `cargo check -p boternity-infra` -- AnthropicProvider compiles and implements LlmProvider trait. Verify that `secrecy::SecretString` is used for API key (grep for "SecretString" in client.rs).
  </verify>
  <done>AnthropicProvider implements LlmProvider with complete() sending POST to Anthropic Messages API and converting the response. API key is wrapped in SecretString. Anthropic-specific types handle all SSE event variants.</done>
</task>

<task type="auto">
  <name>Task 2: Implement SSE streaming state machine</name>
  <files>
    crates/boternity-infra/src/llm/anthropic/streaming.rs
  </files>
  <action>
Implement the SSE stream state machine following RESEARCH.md Pattern 2 exactly. This is the most critical piece of the LLM integration.

**streaming.rs:**
Create `pub fn create_anthropic_stream(client: &reqwest::Client, url: &str, body: AnthropicRequest, api_key: &secrecy::SecretString) -> Pin<Box<dyn Stream<Item = Result<StreamEvent, LlmError>> + Send + 'static>>`

Implementation using `async_stream::try_stream!` macro:
1. Clone client, url, and extract API key (expose_secret) into owned values for 'static lifetime
2. Build the POST request with headers (x-api-key, anthropic-version "2023-06-01", content-type application/json)
3. Create `reqwest_eventsource::EventSource::new(request)` -- NOTE: EventSource::new takes a RequestBuilder. Use `reqwest_eventsource::Event` for the event enum.
4. Initialize `StreamState` struct with:
   - `tool_input_buffers: HashMap<u32, ToolUseAccumulator>` for accumulating tool input JSON per content block index
   - `message_id: Option<String>`
   - `model: Option<String>`
5. Loop with `while let Some(event) = es.next().await`:
   - `Ok(Event::Open)` -> yield `StreamEvent::Connected`
   - `Ok(Event::Message(msg))` -> match on `msg.event.as_str()`:
     - `"message_start"` -> deserialize msg.data as MessageStartPayload, store message_id/model, yield Usage if present
     - `"content_block_start"` -> deserialize, if tool_use type then insert ToolUseAccumulator into buffers, yield ContentBlockStart
     - `"content_block_delta"` -> deserialize, match delta type:
       - text_delta -> yield StreamEvent::TextDelta
       - thinking_delta -> yield StreamEvent::ThinkingDelta
       - input_json_delta -> append partial_json to tool_input_buffers[index].json_buffer
       - signature_delta -> ignore (skip)
     - `"content_block_stop"` -> if index has ToolUseAccumulator, remove it, parse json_buffer into serde_json::Value (empty object if buffer is empty), yield ToolUseComplete. Always yield ContentBlockStop.
     - `"message_delta"` -> deserialize, map stop_reason string to StopReason enum, yield Usage, yield MessageDelta
     - `"message_stop"` -> yield StreamEvent::Done
     - `"ping"` -> ignore (keepalive)
     - `"error"` -> deserialize error, map error_type to LlmError variant (overloaded_error -> Overloaded, rate_limit_error -> RateLimited, authentication_error -> AuthenticationFailed, _ -> Provider), return Err
     - unknown event type -> log warning with tracing::warn!, skip (forward-compatible per Anthropic versioning policy)
   - `Err(reqwest_eventsource::Error::StreamEnded)` -> break
   - `Err(e)` -> return Err(LlmError::Stream(e.to_string()))

**ToolUseAccumulator** struct: id (String), name (String), json_buffer (String)

The deserialization of each SSE event payload is type-specific. Create small payload structs:
- `MessageStartPayload { message: AnthropicMessageObj }`
- `ContentBlockStartPayload { index: u32, content_block: AnthropicContentBlock }`
- `ContentBlockDeltaPayload { index: u32, delta: AnthropicDelta }`
- `ContentBlockStopPayload { index: u32 }`
- `MessageDeltaPayload { delta: MessageDeltaObj, usage: AnthropicUsage }`
- `MessageDeltaObj { stop_reason: Option<String> }`
- `ErrorPayload { error: AnthropicError }`

Important: The SSE event type string (msg.event) determines WHICH payload struct to deserialize msg.data into. This is NOT serde tag-based -- it's a manual match.

Add `use tracing::warn;` for unknown event logging.
  </action>
  <verify>
Run `cargo check -p boternity-infra` -- streaming.rs compiles. Verify the try_stream! macro generates a valid stream. Check that all 8 SSE event types are handled (message_start, content_block_start, content_block_delta, content_block_stop, message_delta, message_stop, ping, error).
  </verify>
  <done>SSE state machine correctly handles all Anthropic streaming event types. Tool use JSON fragments are accumulated per content block index. Error events map to typed LlmError variants. Unknown events are logged and skipped for forward compatibility.</done>
</task>

</tasks>

<verification>
1. `cargo check -p boternity-infra` passes
2. AnthropicProvider implements LlmProvider trait
3. SSE state machine handles all 8 Anthropic event types
4. Tool input JSON accumulation works (buffer per content block index, parse on stop)
5. API key uses secrecy::SecretString, never logged
6. Unknown SSE events are warned and skipped (not panicked)
7. Error events map to typed LlmError variants
</verification>

<success_criteria>
- AnthropicProvider compiles and implements LlmProvider
- SSE streaming returns a Pin<Box<dyn Stream<Item = Result<StreamEvent, LlmError>>>>
- All 8 Anthropic SSE event types are handled
- Tool use accumulation is correct (buffer per index, parse on content_block_stop)
- API key is SecretString, never appears in Debug output or logs
- `cargo check --workspace` passes
</success_criteria>

<output>
After completion, create `.planning/phases/02-single-agent-chat-llm/02-03-SUMMARY.md`
</output>
