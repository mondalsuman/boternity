---
phase: 03-multi-provider-memory
plan: 10
type: execute
wave: 3
depends_on: ["03-04", "03-05"]
files_modified:
  - crates/boternity-infra/src/storage/mod.rs
  - crates/boternity-infra/src/storage/filesystem.rs
  - crates/boternity-infra/src/storage/chunker.rs
  - crates/boternity-infra/src/storage/indexer.rs
  - crates/boternity-infra/src/lib.rs
autonomous: true

must_haves:
  truths:
    - "Files stored at ~/.boternity/bots/{slug}/files/ with version history"
    - "Any file type accepted up to 50MB per file"
    - "Text files automatically chunked and embedded in LanceDB for semantic search"
    - "File version history preserved in .versions/ directory"
    - "FileStore trait fully implemented with save/get/delete/list/versions"
    - "Markdown files use MarkdownSplitter, plain text uses TextSplitter"
  artifacts:
    - path: "crates/boternity-infra/src/storage/filesystem.rs"
      provides: "LocalFileStore implementing FileStore trait"
      contains: "impl FileStore for LocalFileStore"
    - path: "crates/boternity-infra/src/storage/chunker.rs"
      provides: "Semantic text chunker using text-splitter"
      contains: "chunk_text_file"
    - path: "crates/boternity-infra/src/storage/indexer.rs"
      provides: "File indexer that chunks and embeds text files in LanceDB"
      contains: "FileIndexer"
  key_links:
    - from: "crates/boternity-infra/src/storage/filesystem.rs"
      to: "crates/boternity-core/src/storage/file_store.rs"
      via: "implements FileStore trait"
      pattern: "impl FileStore for LocalFileStore"
    - from: "crates/boternity-infra/src/storage/indexer.rs"
      to: "crates/boternity-infra/src/vector/lance.rs"
      via: "stores file chunk embeddings in LanceDB"
      pattern: "file_chunks_table_name"
    - from: "crates/boternity-infra/src/storage/chunker.rs"
      to: "text-splitter crate"
      via: "uses TextSplitter and MarkdownSplitter"
      pattern: "TextSplitter"
---

<objective>
Implement per-bot file storage with version history and semantic text indexing.

Purpose: Bots can store files (text, images, code, PDFs) and automatically index text content for semantic search (MEMO-06). Files become a personal knowledge base -- uploaded text is chunked, embedded, and searchable alongside memories.
Output: LocalFileStore implementing FileStore, text chunker using text-splitter, and file indexer that embeds chunks in LanceDB.
</objective>

<execution_context>
@/Users/smxaz7/.claude/get-shit-done/workflows/execute-plan.md
@/Users/smxaz7/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-multi-provider-memory/03-RESEARCH.md
@.planning/phases/03-multi-provider-memory/03-CONTEXT.md
@.planning/phases/03-multi-provider-memory/03-04-SUMMARY.md
@.planning/phases/03-multi-provider-memory/03-05-SUMMARY.md
@crates/boternity-core/src/storage/file_store.rs
@crates/boternity-infra/src/sqlite/file_metadata.rs
@crates/boternity-infra/src/vector/lance.rs
@crates/boternity-infra/src/vector/schema.rs
@crates/boternity-infra/src/filesystem.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement file storage with version history</name>
  <files>
    crates/boternity-infra/src/storage/mod.rs
    crates/boternity-infra/src/storage/filesystem.rs
    crates/boternity-infra/src/lib.rs
  </files>
  <action>
Create `crates/boternity-infra/src/storage/mod.rs`: `pub mod filesystem; pub mod chunker; pub mod indexer;`
Update `crates/boternity-infra/src/lib.rs`: add `pub mod storage;`

Create `crates/boternity-infra/src/storage/filesystem.rs`:

1. `LocalFileStore` struct:
   - `base_dir: PathBuf` (typically ~/.boternity/bots/)
   - `metadata: SqliteFileMetadataStore`

2. `LocalFileStore::new(base_dir: PathBuf, metadata: SqliteFileMetadataStore) -> Self`

3. Helpers:
   - `fn file_path(&self, bot_slug: &str, filename: &str) -> PathBuf` -> base_dir/bot_slug/files/filename
   - `fn versions_dir(&self, bot_slug: &str, filename: &str) -> PathBuf` -> base_dir/bot_slug/files/.versions/filename/
   - `fn is_text_file(mime_type: &str) -> bool` -- check if text/, application/json, application/javascript, etc.

4. Implement `FileStore` for `LocalFileStore`:

   - `save_file(bot_id, filename, data)`:
     - Check size: data.len() <= MAX_FILE_SIZE_BYTES (50MB), return error if exceeded
     - Detect MIME type from filename extension (use simple match: .txt -> text/plain, .md -> text/markdown, .json -> application/json, .rs/.py/.js etc -> text/x-code, images -> image/*, default -> application/octet-stream)
     - Check if file already exists via metadata:
       - If exists: create version backup first (copy current file to .versions/{filename}/v{N}), increment version
       - If new: version = 1
     - Write file to disk: ensure parent dirs exist, write data
     - Save/update metadata in SQLite (StorageFile)
     - Save FileVersion record
     - Return StorageFile

   - `get_file(bot_id, filename)`:
     - Read file from disk path
     - Return bytes

   - `delete_file(bot_id, filename)`:
     - Delete file from disk
     - Delete .versions/ directory for this file
     - Delete metadata (CASCADE handles versions)

   - `list_files(bot_id)`:
     - Query metadata for all files for this bot
     - Return Vec<StorageFile>

   - `get_file_info(bot_id, filename)`:
     - Query metadata
     - Return StorageFile

   - `get_versions(file_id)`:
     - Query file version metadata
     - Return Vec<FileVersion>

Note: The FileStore trait takes bot_id (Uuid). The LocalFileStore needs to resolve bot_id -> slug for the filesystem path. Accept a `fn resolve_slug(bot_id: Uuid) -> String` callback or look up via bot repo. Simplest: store a mapping or accept slug alongside bot_id.
  </action>
  <verify>`cargo check -p boternity-infra` compiles. File save/get/delete roundtrip works in test.</verify>
  <done>LocalFileStore implements FileStore with filesystem-backed storage, automatic version history, MIME type detection, and 50MB size limit enforcement.</done>
</task>

<task type="auto">
  <name>Task 2: Implement text chunking and file indexing</name>
  <files>
    crates/boternity-infra/src/storage/chunker.rs
    crates/boternity-infra/src/storage/indexer.rs
  </files>
  <action>
Create `crates/boternity-infra/src/storage/chunker.rs`:

1. `pub fn chunk_text_file(content: &str, is_markdown: bool) -> Vec<String>`:
   - Per RESEARCH.md Pattern 9 and discretion recommendation: 512 chars per chunk with paragraph boundary preference
   - Use `ChunkConfig::new(512)` from text-splitter
   - If is_markdown: use `MarkdownSplitter::new(config)`
   - Else: use `TextSplitter::new(config)`
   - Call `splitter.chunks(content).map(|s| s.to_string()).collect()`

2. `pub fn detect_markdown(filename: &str) -> bool`:
   - Check extension: .md, .markdown, .mdx -> true, else false

Create `crates/boternity-infra/src/storage/indexer.rs`:

1. `FileIndexer` struct:
   - `store: Arc<LanceVectorStore>`
   - `embedder: Arc<dyn EmbedderDyn + Send + Sync>` (or concrete FastEmbedEmbedder)

2. `FileIndexer::new(store, embedder) -> Self`

3. `pub async fn index_file(&self, bot_id: &Uuid, file_id: &Uuid, filename: &str, content: &str) -> Result<usize, ...>`:
   - Detect markdown: `detect_markdown(filename)`
   - Chunk: `chunk_text_file(content, is_markdown)`
   - Embed all chunks in batch: `embedder.embed(chunks)` (batched for efficiency per RESEARCH.md Pitfall 7)
   - Build RecordBatch from FileChunk data + embeddings using file_chunks_schema
   - Get/create file_chunks table for this bot: `file_chunks_table_name(bot_id)`
   - Insert batch
   - Return number of chunks indexed

4. `pub async fn deindex_file(&self, bot_id: &Uuid, file_id: &Uuid) -> Result<(), ...>`:
   - Delete all chunks for this file: `table.delete(&format!("file_id = '{}'", file_id)).await`

5. `pub async fn reindex_file(&self, bot_id: &Uuid, file_id: &Uuid, filename: &str, content: &str) -> Result<usize, ...>`:
   - Deindex then index

6. `pub async fn search_file_chunks(&self, bot_id: &Uuid, query_embedding: &[f32], limit: usize) -> Result<Vec<FileChunk>, ...>`:
   - Query file_chunks table with vector search
   - Return matching chunks with file context

Add integration test:
- Create a text file, chunk it, embed chunks, store in LanceDB
- Search with relevant query -> returns matching chunk
- Delete file -> chunks removed
  </action>
  <verify>`cargo test -p boternity-infra -- storage` passes. Text files are chunked, embedded, and searchable.</verify>
  <done>Text files are semantically chunked (512 chars, paragraph boundaries) and indexed in LanceDB. File chunks are searchable via vector similarity. Markdown files use MarkdownSplitter.</done>
</task>

</tasks>

<verification>
- `cargo check --workspace` compiles
- `cargo test -p boternity-infra -- storage` passes
- File save/get/delete roundtrip works
- Version history created on file update
- Text files chunked with paragraph boundaries
- File chunks searchable via LanceDB vector search
</verification>

<success_criteria>
Per-bot file storage operational with version history. Text files automatically chunked and embedded for semantic search. Any file type accepted up to 50MB. Markdown files use specialized splitter.
</success_criteria>

<output>
After completion, create `.planning/phases/03-multi-provider-memory/03-10-SUMMARY.md`
</output>
