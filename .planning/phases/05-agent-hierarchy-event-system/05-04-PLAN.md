---
phase: 05-agent-hierarchy-event-system
plan: 04
type: execute
wave: 3
depends_on: ["05-02", "05-03"]
files_modified:
  - crates/boternity-core/src/agent/orchestrator.rs
  - crates/boternity-core/src/agent/mod.rs
autonomous: true

must_haves:
  truths:
    - "AgentOrchestrator executes a user message and returns a final synthesized response"
    - "When the LLM emits <spawn_agents>, sub-agents are spawned in parallel or sequential mode"
    - "Sub-agents at depth 3 can execute but cannot spawn further children"
    - "Failed sub-agents are retried once, then skipped with partial results per user decision"
    - "All agent lifecycle events are published to the EventBus via explicit event_bus.publish() calls"
    - "Cancellation stops all running sub-agents within the request tree"
    - "Budget exhaustion gracefully stops with partial results per user decision"
    - "Sub-agent memory creation publishes MemoryCreated events with agent_id for source_agent_id tagging"
  artifacts:
    - path: "crates/boternity-core/src/agent/orchestrator.rs"
      provides: "AgentOrchestrator with execute(), execute_parallel(), execute_sequential(), synthesize()"
      contains: "pub struct AgentOrchestrator"
      min_lines: 200
  key_links:
    - from: "crates/boternity-core/src/agent/orchestrator.rs"
      to: "crates/boternity-core/src/agent/engine.rs"
      via: "uses AgentEngine for LLM calls"
      pattern: "AgentEngine"
    - from: "crates/boternity-core/src/agent/orchestrator.rs"
      to: "crates/boternity-core/src/event/bus.rs"
      via: "publishes AgentEvent to EventBus at every lifecycle point"
      pattern: "event_bus\\.publish\\(AgentEvent::"
    - from: "crates/boternity-core/src/agent/orchestrator.rs"
      to: "crates/boternity-core/src/agent/request_context.rs"
      via: "uses RequestContext for budget + cancellation"
      pattern: "RequestContext"
    - from: "crates/boternity-core/src/agent/orchestrator.rs"
      to: "crates/boternity-core/src/agent/spawner.rs"
      via: "parse_spawn_instructions from LLM response"
      pattern: "parse_spawn_instructions"
    - from: "crates/boternity-core/src/agent/orchestrator.rs"
      to: "crates/boternity-types/src/memory.rs"
      via: "passes agent_id to memory extraction for source_agent_id tagging"
      pattern: "source_agent_id"
---

<objective>
Build the AgentOrchestrator -- the central component that manages the full lifecycle of a user request: initial LLM call, spawn detection, sub-agent execution (parallel or sequential), retry logic, budget enforcement, cancellation, and synthesis.

Purpose: This is the heart of Phase 5. Everything else (types, primitives, parsers) exists to support this component. The orchestrator turns a single user message into a potentially multi-agent execution tree.
Output: orchestrator.rs with comprehensive orchestration logic.
</objective>

<execution_context>
@/Users/smxaz7/.claude/get-shit-done/workflows/execute-plan.md
@/Users/smxaz7/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-agent-hierarchy-event-system/05-RESEARCH.md
@.planning/phases/05-agent-hierarchy-event-system/05-01-SUMMARY.md
@.planning/phases/05-agent-hierarchy-event-system/05-02-SUMMARY.md
@.planning/phases/05-agent-hierarchy-event-system/05-03-SUMMARY.md
@crates/boternity-core/src/agent/engine.rs
@crates/boternity-core/src/agent/context.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: AgentOrchestrator core structure and parallel execution</name>
  <files>
    crates/boternity-core/src/agent/orchestrator.rs
    crates/boternity-core/src/agent/mod.rs
  </files>
  <action>
**Create `crates/boternity-core/src/agent/orchestrator.rs`:**

The orchestrator manages a full request lifecycle. It does NOT own the LLM provider -- it receives a `BoxLlmProvider` (or FallbackChain) per-request. It does NOT store long-lived state -- each `execute()` call is independent.

```rust
use std::time::Instant;
use tokio::task::JoinSet;
use uuid::Uuid;
use futures_util::StreamExt;

use boternity_types::agent::{AgentStatus, SpawnMode, SubAgentResult};
use boternity_types::event::AgentEvent;

use crate::agent::budget::BudgetStatus;
use crate::agent::context::AgentContext;
use crate::agent::request_context::RequestContext;
use crate::agent::spawner::{parse_spawn_instructions, extract_text_before_spawn};
use crate::event::EventBus;
use crate::llm::box_provider::BoxLlmProvider;
```

**`AgentOrchestrator` struct:**
- No fields -- it's a coordinator, not a container. All state comes via parameters.
- Alternative: make it a zero-sized struct with associated methods, or use a builder.

Actually, give it fields for reusable config:
- `max_depth: u8` -- default 3, the hard cap per user constraint
- Derive Clone

**Key methods:**

1. `pub async fn execute(...)` -- the main entry point

Parameters:
- `&self`
- `provider: &BoxLlmProvider` (or &FallbackChain -- use BoxLlmProvider for now, the chat handler already uses FallbackChain.select_stream())
- `context: &mut AgentContext` -- root agent context (mutable for adding messages)
- `user_message: &str`
- `request_ctx: &RequestContext`
- `event_bus: &EventBus`
- `budget_continue_rx: Option<tokio::sync::oneshot::Receiver<bool>>` -- for budget pause prompt (None = auto-continue)

Returns: `Result<OrchestratorResult, OrchestratorError>`

The flow:
a) Use `SystemPromptBuilder::build_with_capabilities(...)` to rebuild the context's system prompt with `<agent_capabilities>` section
b) Build CompletionRequest from context + user_message
c) Call `provider.stream(request)` and collect the full response. While streaming:
   - For each text delta chunk, publish a budget update:
     ```rust
     let status = request_ctx.budget.add_tokens(chunk_tokens);
     event_bus.publish(AgentEvent::BudgetUpdate {
         request_id: request_ctx.request_id,
         tokens_used: request_ctx.budget.tokens_used(),
         budget_total: request_ctx.budget.total_budget(),
         percentage: request_ctx.budget.percentage(),
     });
     ```
d) After collection, check response for spawn instructions via `parse_spawn_instructions()`
e) If NO spawn instructions: return the response directly as OrchestratorResult (simple path, same as current chat)
f) If spawn instructions found:
   - Check depth: if `request_ctx.depth >= self.max_depth`:
     ```rust
     event_bus.publish(AgentEvent::DepthLimitReached {
         agent_id: root_agent_id,
         attempted_depth: request_ctx.depth + 1,
         max_depth: self.max_depth,
     });
     ```
     Return what we have.
   - Check cycle detector for each task:
     ```rust
     if let CycleCheckResult::CycleDetected { description } = request_ctx.cycle_detector.check_and_register(&task, request_ctx.depth) {
         event_bus.publish(AgentEvent::CycleDetected {
             agent_id: root_agent_id,
             cycle_description: description,
         });
         // Skip this task
     }
     ```
   - Execute sub-agents based on SpawnMode (parallel or sequential)
   - After all sub-agents complete, publish synthesis start and do synthesis call (step g):
     ```rust
     event_bus.publish(AgentEvent::SynthesisStarted {
         request_id: request_ctx.request_id,
     });
     ```
g) Synthesis: Build a new CompletionRequest with the root context, including sub-agent results as a `<sub_agent_results>` XML block in the user message. The bot synthesizes a cohesive response. Per user decision: "Bot always produces a synthesis response after all sub-agents complete."

2. `async fn execute_parallel(...)` -- runs tasks via JoinSet

Parameters: tasks Vec<String>, parent context, provider (cloned for each), request_ctx, event_bus

Flow:
- Create JoinSet
- For each task (with index): create child context via `context.child_for_task(task, depth)`, create child RequestContext via `request_ctx.child()`, assign `agent_id = Uuid::now_v7()`, spawn into JoinSet
- Each spawned task: immediately publish AgentSpawned:
  ```rust
  event_bus.publish(AgentEvent::AgentSpawned {
      agent_id,
      parent_id: Some(parent_agent_id),
      task_description: task.clone(),
      depth: child_request_ctx.depth,
      index: i,
      total: tasks.len(),
  });
  ```
  Then run `execute_single_agent()`. On completion:
  ```rust
  event_bus.publish(AgentEvent::AgentCompleted {
      agent_id,
      result_summary: result.response.clone().unwrap_or_default(),
      tokens_used: result.tokens_used,
      duration_ms: result.duration_ms,
  });
  ```
  On failure:
  ```rust
  event_bus.publish(AgentEvent::AgentFailed {
      agent_id,
      error: err.to_string(),
      will_retry: attempt == 0, // true on first failure (will retry), false on second
  });
  ```
- Collect results via `set.join_next().await` loop
- Handle JoinError (panicked task) -> convert to failed SubAgentResult (pitfall 8)
- Return Vec<SubAgentResult>

3. `async fn execute_sequential(...)` -- runs tasks one-by-one

Parameters: same as parallel

Flow:
- For each task in order:
  - Create child context. Per user decision: "Sequential sub-agents see only the immediately prior sub-agent's result (not the full chain)." So if there's a previous result, inject it into the child context's conversation history as a user message.
  - Publish AgentSpawned (same pattern as parallel above)
  - Run `execute_single_agent()`
  - Publish AgentCompleted or AgentFailed (same patterns as parallel above)
  - Check cancellation between tasks
  - Check budget between tasks
- Return Vec<SubAgentResult>

4. `async fn execute_single_agent(...)` -- runs one sub-agent LLM call

Parameters: child context, provider, request_ctx, event_bus, agent_id

Flow:
- Wrap in `tokio::select!` with cancellation token. On cancellation:
  ```rust
  event_bus.publish(AgentEvent::AgentCancelled {
      agent_id,
      reason: "Request cancelled by user".to_string(),
  });
  ```
- Build CompletionRequest from child context with the task as user message
- Stream the response, publishing AgentTextDelta for each token:
  ```rust
  event_bus.publish(AgentEvent::AgentTextDelta {
      agent_id,
      text: delta.clone(),
  });
  ```
- Track tokens via request_ctx.budget.add_tokens(). After each token batch, publish BudgetUpdate:
  ```rust
  let status = request_ctx.budget.add_tokens(tokens);
  event_bus.publish(AgentEvent::BudgetUpdate {
      request_id: request_ctx.request_id,
      tokens_used: request_ctx.budget.tokens_used(),
      budget_total: request_ctx.budget.total_budget(),
      percentage: request_ctx.budget.percentage(),
  });
  ```
- On budget Warning:
  ```rust
  event_bus.publish(AgentEvent::BudgetWarning {
      request_id: request_ctx.request_id,
      tokens_used: request_ctx.budget.tokens_used(),
      budget_total: request_ctx.budget.total_budget(),
  });
  ```
- On budget Exhausted:
  ```rust
  event_bus.publish(AgentEvent::BudgetExhausted {
      request_id: request_ctx.request_id,
      tokens_used: request_ctx.budget.tokens_used(),
      budget_total: request_ctx.budget.total_budget(),
      completed_agents: vec![], // filled by caller with completed agent IDs
      incomplete_agents: vec![agent_id],
  });
  ```
  Stop streaming and return partial result.
- Check if sub-agent response also contains spawn instructions (recursive spawning). If so, recursively call execute on the child.
- Per user decision: "On sub-agent failure: retry once, then skip and continue with remaining sub-agents + partial results." Implement retry logic: catch errors, retry once, on second failure return SubAgentResult with status Failed.
- Return SubAgentResult

**Sub-agent memory creation (locked user decision: "Sub-agents have full memory access -- can both recall and create memories, tagged with which agent created them"):**

The orchestrator must support memory creation from sub-agents. The approach:

- `execute_single_agent()` accepts an optional `agent_id: Uuid` parameter that identifies the executing sub-agent.
- After a sub-agent's response is collected, if the caller (chat handler or a future memory extraction step) runs memory extraction on that response, the `agent_id` is passed through as `source_agent_id` on the resulting `MemoryEntry`.
- The `OrchestratorResult` includes a `memory_context: Vec<AgentMemoryContext>` field (alongside agent_tree) where:
  ```rust
  pub struct AgentMemoryContext {
      pub agent_id: Uuid,
      pub response_text: String,
      pub task_description: String,
  }
  ```
  This gives the caller (chat handler) all the information needed to run memory extraction per-agent with the correct `source_agent_id`.
- When the chat handler extracts memories from a sub-agent's response, it sets `source_agent_id: Some(agent_id)` on each `MemoryEntry` created, and publishes:
  ```rust
  event_bus.publish(AgentEvent::MemoryCreated {
      agent_id,
      fact: extracted_fact.clone(),
  });
  ```
- Note: The actual memory extraction call (using the LLM utility) happens in the chat handler layer, not inside the orchestrator itself. The orchestrator's job is to (1) surface `AgentMemoryContext` so the caller knows which agent produced which text, and (2) provide the `event_bus` reference so the caller can publish `MemoryCreated` events with the correct `agent_id`.
- Sub-agents also have full memory RECALL: child contexts are built with the same recalled memories as the parent (via `context.child_for_task()` which inherits the `<long_term_memory>` section from the parent's system prompt).

5. `fn build_synthesis_prompt(results: &[SubAgentResult]) -> String` -- builds the XML block of sub-agent results for the synthesis call

Format:
```xml
<sub_agent_results>
  <result task="..." status="completed">
    [agent response text]
  </result>
  <result task="..." status="failed">
    Error: [error message]
  </result>
</sub_agent_results>

Based on these sub-agent results, synthesize a cohesive response that integrates all findings. Address any gaps from failed sub-agents.
```

**`OrchestratorResult` struct:**
- `pre_spawn_text: Option<String>` -- text before spawn block (if any)
- `sub_agent_results: Vec<SubAgentResult>` -- results from sub-agents (empty if no spawn)
- `synthesis: Option<String>` -- the synthesis response (None if no spawn)
- `final_response: String` -- the complete response to show the user (either direct response or synthesis)
- `total_tokens_used: u32`
- `agent_tree: Vec<boternity_types::agent::AgentNode>` -- flat list of all agents for tree rendering
- `memory_contexts: Vec<AgentMemoryContext>` -- per-agent response data for memory extraction with source_agent_id tagging

**`AgentMemoryContext` struct:**
- `agent_id: Uuid` -- the sub-agent that produced this response
- `response_text: String` -- the sub-agent's full response text
- `task_description: String` -- what the sub-agent was asked to do

**`OrchestratorError` enum (thiserror):**
- `LlmError(LlmError)` -- from provider
- `BudgetExhausted { partial_results: Vec<SubAgentResult>, tokens_used: u32 }` -- budget exceeded
- `Cancelled` -- user cancelled
- `Internal(String)` -- unexpected errors

**Update `crates/boternity-core/src/agent/mod.rs`:**
Add `pub mod orchestrator;`

**Tests:**
Due to the complexity of mocking LLM providers, keep orchestrator tests focused on:
- `build_synthesis_prompt` with various SubAgentResult combinations
- OrchestratorResult construction
- AgentMemoryContext population from SubAgentResults
- Unit tests for helper methods (not full integration tests -- those happen in execution)

Note: Full integration testing of the orchestrator requires a mock LLM provider that returns specific responses. This is acceptable as a gap -- the real test is in the chat handler and CLI integration (plans 07 and 08).
  </action>
  <verify>Run `cargo test -p boternity-core -- orchestrator` -- unit tests pass. Run `cargo check --workspace` -- compiles. Verify the orchestrator module is exported. Grep for `event_bus.publish(AgentEvent::` in orchestrator.rs to confirm explicit event publishing at all lifecycle points (spawn, text delta, completion, failure, cancellation, budget update, budget warning, budget exhausted, depth limit, cycle detected, synthesis started).</verify>
  <done>AgentOrchestrator manages full request lifecycle: initial LLM call, spawn detection, parallel/sequential sub-agent execution with JoinSet, retry-once logic, budget enforcement, cancellation, and synthesis. Explicit event_bus.publish(AgentEvent::...) calls at every lifecycle point: AgentSpawned, AgentTextDelta, AgentCompleted, AgentFailed, AgentCancelled, BudgetUpdate, BudgetWarning, BudgetExhausted, DepthLimitReached, CycleDetected, SynthesisStarted. OrchestratorResult includes memory_contexts for sub-agent memory extraction with source_agent_id tagging per locked user decision.</done>
</task>

</tasks>

<verification>
- `cargo check --workspace` compiles
- `cargo test -p boternity-core -- orchestrator` passes
- orchestrator.rs has execute(), execute_parallel(), execute_sequential(), execute_single_agent()
- OrchestratorResult has pre_spawn_text, sub_agent_results, synthesis, final_response, memory_contexts
- AgentMemoryContext struct exists with agent_id, response_text, task_description
- build_synthesis_prompt produces well-formed XML
- Module is exported from agent/mod.rs
- `grep -c 'event_bus.publish(AgentEvent::' orchestrator.rs` returns 11+ (one for each event type)
- orchestrator.rs references source_agent_id for memory tagging
</verification>

<success_criteria>
The AgentOrchestrator is the fully functional orchestration engine. It handles the complete lifecycle: LLM call -> spawn detection -> sub-agent execution -> budget checks -> retry -> synthesis -> final response. All events published to EventBus via explicit event_bus.publish(AgentEvent::...) calls for real-time UI. Sub-agent memory creation supported via AgentMemoryContext in OrchestratorResult, enabling the chat handler to extract memories with correct source_agent_id tagging.
</success_criteria>

<output>
After completion, create `.planning/phases/05-agent-hierarchy-event-system/05-04-SUMMARY.md`
</output>
