---
phase: 05-agent-hierarchy-event-system
plan: 04
type: execute
wave: 3
depends_on: ["05-02", "05-03"]
files_modified:
  - crates/boternity-core/src/agent/orchestrator.rs
  - crates/boternity-core/src/agent/mod.rs
autonomous: true

must_haves:
  truths:
    - "AgentOrchestrator executes a user message and returns a final synthesized response"
    - "When the LLM emits <spawn_agents>, sub-agents are spawned in parallel or sequential mode"
    - "Sub-agents at depth 3 can execute but cannot spawn further children"
    - "Failed sub-agents are retried once, then skipped with partial results per user decision"
    - "All agent lifecycle events are published to the EventBus"
    - "Cancellation stops all running sub-agents within the request tree"
    - "Budget exhaustion gracefully stops with partial results per user decision"
  artifacts:
    - path: "crates/boternity-core/src/agent/orchestrator.rs"
      provides: "AgentOrchestrator with execute(), execute_parallel(), execute_sequential(), synthesize()"
      contains: "pub struct AgentOrchestrator"
      min_lines: 200
  key_links:
    - from: "crates/boternity-core/src/agent/orchestrator.rs"
      to: "crates/boternity-core/src/agent/engine.rs"
      via: "uses AgentEngine for LLM calls"
      pattern: "AgentEngine"
    - from: "crates/boternity-core/src/agent/orchestrator.rs"
      to: "crates/boternity-core/src/event/bus.rs"
      via: "publishes AgentEvent to EventBus"
      pattern: "event_bus\\.publish"
    - from: "crates/boternity-core/src/agent/orchestrator.rs"
      to: "crates/boternity-core/src/agent/request_context.rs"
      via: "uses RequestContext for budget + cancellation"
      pattern: "RequestContext"
    - from: "crates/boternity-core/src/agent/orchestrator.rs"
      to: "crates/boternity-core/src/agent/spawner.rs"
      via: "parse_spawn_instructions from LLM response"
      pattern: "parse_spawn_instructions"
---

<objective>
Build the AgentOrchestrator -- the central component that manages the full lifecycle of a user request: initial LLM call, spawn detection, sub-agent execution (parallel or sequential), retry logic, budget enforcement, cancellation, and synthesis.

Purpose: This is the heart of Phase 5. Everything else (types, primitives, parsers) exists to support this component. The orchestrator turns a single user message into a potentially multi-agent execution tree.
Output: orchestrator.rs with comprehensive orchestration logic.
</objective>

<execution_context>
@/Users/smxaz7/.claude/get-shit-done/workflows/execute-plan.md
@/Users/smxaz7/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-agent-hierarchy-event-system/05-RESEARCH.md
@.planning/phases/05-agent-hierarchy-event-system/05-01-SUMMARY.md
@.planning/phases/05-agent-hierarchy-event-system/05-02-SUMMARY.md
@.planning/phases/05-agent-hierarchy-event-system/05-03-SUMMARY.md
@crates/boternity-core/src/agent/engine.rs
@crates/boternity-core/src/agent/context.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: AgentOrchestrator core structure and parallel execution</name>
  <files>
    crates/boternity-core/src/agent/orchestrator.rs
    crates/boternity-core/src/agent/mod.rs
  </files>
  <action>
**Create `crates/boternity-core/src/agent/orchestrator.rs`:**

The orchestrator manages a full request lifecycle. It does NOT own the LLM provider -- it receives a `BoxLlmProvider` (or FallbackChain) per-request. It does NOT store long-lived state -- each `execute()` call is independent.

```rust
use std::time::Instant;
use tokio::task::JoinSet;
use uuid::Uuid;
use futures_util::StreamExt;

use boternity_types::agent::{AgentStatus, SpawnMode, SubAgentResult};
use boternity_types::event::AgentEvent;

use crate::agent::budget::BudgetStatus;
use crate::agent::context::AgentContext;
use crate::agent::request_context::RequestContext;
use crate::agent::spawner::{parse_spawn_instructions, extract_text_before_spawn};
use crate::event::EventBus;
use crate::llm::box_provider::BoxLlmProvider;
```

**`AgentOrchestrator` struct:**
- No fields -- it's a coordinator, not a container. All state comes via parameters.
- Alternative: make it a zero-sized struct with associated methods, or use a builder.

Actually, give it fields for reusable config:
- `max_depth: u8` -- default 3, the hard cap per user constraint
- Derive Clone

**Key methods:**

1. `pub async fn execute(...)` -- the main entry point

Parameters:
- `&self`
- `provider: &BoxLlmProvider` (or &FallbackChain -- use BoxLlmProvider for now, the chat handler already uses FallbackChain.select_stream())
- `context: &mut AgentContext` -- root agent context (mutable for adding messages)
- `user_message: &str`
- `request_ctx: &RequestContext`
- `event_bus: &EventBus`
- `budget_continue_rx: Option<tokio::sync::oneshot::Receiver<bool>>` -- for budget pause prompt (None = auto-continue)

Returns: `Result<OrchestratorResult, OrchestratorError>`

The flow:
a) Use `SystemPromptBuilder::build_with_capabilities(...)` to rebuild the context's system prompt with `<agent_capabilities>` section
b) Build CompletionRequest from context + user_message
c) Call `provider.stream(request)` and collect the full response (consuming text deltas, tracking usage via request_ctx.budget.add_tokens())
d) After collection, check response for spawn instructions via `parse_spawn_instructions()`
e) If NO spawn instructions: return the response directly as OrchestratorResult (simple path, same as current chat)
f) If spawn instructions found:
   - Publish `AgentEvent::AgentSpawned` for the pre-spawn message
   - Check depth: if `request_ctx.depth >= self.max_depth` -> publish DepthLimitReached, return what we have
   - Check cycle detector for each task
   - Execute sub-agents based on SpawnMode (parallel or sequential)
   - After all sub-agents complete, do synthesis call (step g)
g) Synthesis: Build a new CompletionRequest with the root context, including sub-agent results as a `<sub_agent_results>` XML block in the user message. The bot synthesizes a cohesive response. Per user decision: "Bot always produces a synthesis response after all sub-agents complete."

2. `async fn execute_parallel(...)` -- runs tasks via JoinSet

Parameters: tasks Vec<String>, parent context, provider (cloned for each), request_ctx, event_bus

Flow:
- Create JoinSet
- For each task: create child context via `context.child_for_task(task, depth)`, create child RequestContext via `request_ctx.child()`, spawn into JoinSet
- Each spawned task: publish AgentSpawned, run `execute_single_agent()`, publish AgentCompleted/Failed
- Collect results via `set.join_next().await` loop
- Handle JoinError (panicked task) -> convert to failed SubAgentResult (pitfall 8)
- Return Vec<SubAgentResult>

3. `async fn execute_sequential(...)` -- runs tasks one-by-one

Parameters: same as parallel

Flow:
- For each task in order:
  - Create child context. Per user decision: "Sequential sub-agents see only the immediately prior sub-agent's result (not the full chain)." So if there's a previous result, inject it into the child context's conversation history as a user message.
  - Run `execute_single_agent()`
  - Check cancellation between tasks
  - Check budget between tasks
- Return Vec<SubAgentResult>

4. `async fn execute_single_agent(...)` -- runs one sub-agent LLM call

Parameters: child context, provider, request_ctx, event_bus, agent_id

Flow:
- Wrap in `tokio::select!` with cancellation token
- Build CompletionRequest from child context with the task as user message
- Stream the response, publishing AgentTextDelta events for each token
- Track tokens via request_ctx.budget.add_tokens()
- On budget Warning: publish BudgetWarning
- On budget Exhausted: publish BudgetExhausted, stop
- Check if sub-agent response also contains spawn instructions (recursive spawning). If so, recursively call execute on the child.
- Per user decision: "On sub-agent failure: retry once, then skip and continue with remaining sub-agents + partial results." Implement retry logic: catch errors, retry once, on second failure return SubAgentResult with status Failed.
- Return SubAgentResult

5. `fn build_synthesis_prompt(results: &[SubAgentResult]) -> String` -- builds the XML block of sub-agent results for the synthesis call

Format:
```xml
<sub_agent_results>
  <result task="..." status="completed">
    [agent response text]
  </result>
  <result task="..." status="failed">
    Error: [error message]
  </result>
</sub_agent_results>

Based on these sub-agent results, synthesize a cohesive response that integrates all findings. Address any gaps from failed sub-agents.
```

**`OrchestratorResult` struct:**
- `pre_spawn_text: Option<String>` -- text before spawn block (if any)
- `sub_agent_results: Vec<SubAgentResult>` -- results from sub-agents (empty if no spawn)
- `synthesis: Option<String>` -- the synthesis response (None if no spawn)
- `final_response: String` -- the complete response to show the user (either direct response or synthesis)
- `total_tokens_used: u32`
- `agent_tree: Vec<boternity_types::agent::AgentNode>` -- flat list of all agents for tree rendering

**`OrchestratorError` enum (thiserror):**
- `LlmError(LlmError)` -- from provider
- `BudgetExhausted { partial_results: Vec<SubAgentResult>, tokens_used: u32 }` -- budget exceeded
- `Cancelled` -- user cancelled
- `Internal(String)` -- unexpected errors

**Update `crates/boternity-core/src/agent/mod.rs`:**
Add `pub mod orchestrator;`

**Tests:**
Due to the complexity of mocking LLM providers, keep orchestrator tests focused on:
- `build_synthesis_prompt` with various SubAgentResult combinations
- OrchestratorResult construction
- Unit tests for helper methods (not full integration tests -- those happen in execution)

Note: Full integration testing of the orchestrator requires a mock LLM provider that returns specific responses. This is acceptable as a gap -- the real test is in the chat handler and CLI integration (plans 07 and 08).
  </action>
  <verify>Run `cargo test -p boternity-core -- orchestrator` -- unit tests pass. Run `cargo check --workspace` -- compiles. Verify the orchestrator module is exported.</verify>
  <done>AgentOrchestrator manages full request lifecycle: initial LLM call, spawn detection, parallel/sequential sub-agent execution with JoinSet, retry-once logic, budget enforcement, cancellation, and synthesis. All agent events published to EventBus.</done>
</task>

</tasks>

<verification>
- `cargo check --workspace` compiles
- `cargo test -p boternity-core -- orchestrator` passes
- orchestrator.rs has execute(), execute_parallel(), execute_sequential(), execute_single_agent()
- OrchestratorResult has pre_spawn_text, sub_agent_results, synthesis, final_response
- build_synthesis_prompt produces well-formed XML
- Module is exported from agent/mod.rs
</verification>

<success_criteria>
The AgentOrchestrator is the fully functional orchestration engine. It handles the complete lifecycle: LLM call -> spawn detection -> sub-agent execution -> budget checks -> retry -> synthesis -> final response. All events published to EventBus for real-time UI.
</success_criteria>

<output>
After completion, create `.planning/phases/05-agent-hierarchy-event-system/05-04-SUMMARY.md`
</output>
