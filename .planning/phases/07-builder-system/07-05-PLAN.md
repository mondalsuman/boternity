---
phase: 07-builder-system
plan: 05
type: execute
wave: 3
depends_on: ["07-02", "07-03"]
files_modified:
  - crates/boternity-infra/src/builder/llm_builder.rs
  - crates/boternity-infra/src/builder/mod.rs
  - crates/boternity-infra/src/llm/anthropic/mod.rs
  - crates/boternity-infra/src/llm/bedrock/mod.rs
autonomous: true

must_haves:
  truths:
    - "LlmBuilderAgent calls Claude with structured output and parses BuilderTurn responses"
    - "output_config is wired through Anthropic and Bedrock providers"
    - "Each turn receives accumulated state context via Forge system prompt"
    - "Builder uses non-streaming calls (not streaming) for structured output"
    - "LlmBuilderAgent queries builder memory and passes recalled sessions to the prompt"
  artifacts:
    - path: "crates/boternity-infra/src/builder/llm_builder.rs"
      provides: "LlmBuilderAgent implementing BuilderAgent"
      contains: "impl BuilderAgent for LlmBuilderAgent"
  key_links:
    - from: "crates/boternity-infra/src/builder/llm_builder.rs"
      to: "crates/boternity-core/src/builder/agent.rs"
      via: "implements BuilderAgent trait"
      pattern: "impl BuilderAgent"
    - from: "crates/boternity-infra/src/builder/llm_builder.rs"
      to: "crates/boternity-core/src/agent/engine.rs"
      via: "uses AgentEngine::execute_non_streaming for structured output"
      pattern: "execute_non_streaming"
    - from: "crates/boternity-infra/src/builder/llm_builder.rs"
      to: "crates/boternity-core/src/builder/prompt.rs"
      via: "passes recalled_memories to build_forge_system_prompt"
      pattern: "recalled_memories"
---

<objective>
Implement the LLM-powered builder agent and wire output_config through providers.

Purpose: This is the brain of the builder system -- it calls Claude with structured output schema to get parseable BuilderTurn responses on each turn. Also wires the output_config field through Anthropic and Bedrock providers so the API request includes the JSON schema constraint. The LlmBuilderAgent queries builder memory to pass recalled sessions into the Forge prompt for suggestion-based UX.
Output: LlmBuilderAgent in boternity-infra, output_config wired through both providers.
</objective>

<execution_context>
@/Users/smxaz7/.claude/get-shit-done/workflows/execute-plan.md
@/Users/smxaz7/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-builder-system/07-RESEARCH.md
@.planning/phases/07-builder-system/07-CONTEXT.md
@.planning/phases/07-builder-system/07-01-SUMMARY.md
@.planning/phases/07-builder-system/07-02-SUMMARY.md
@.planning/phases/07-builder-system/07-03-SUMMARY.md
@crates/boternity-types/src/builder.rs
@crates/boternity-types/src/llm.rs
@crates/boternity-core/src/builder/agent.rs
@crates/boternity-core/src/builder/prompt.rs
@crates/boternity-core/src/builder/state.rs
@crates/boternity-core/src/builder/memory.rs
@crates/boternity-core/src/agent/engine.rs
@crates/boternity-infra/src/llm/anthropic/mod.rs
@crates/boternity-infra/src/llm/bedrock/mod.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire output_config through Anthropic and Bedrock providers</name>
  <files>
    crates/boternity-infra/src/llm/anthropic/mod.rs
    crates/boternity-infra/src/llm/bedrock/mod.rs
  </files>
  <action>
    Per research CORRECTION 2, CompletionRequest now has `output_config: Option<OutputConfig>`. This needs to be forwarded to the provider-specific request formats.

    1. **Anthropic provider** (`crates/boternity-infra/src/llm/anthropic/mod.rs`):
    Find the `to_anthropic_request()` or equivalent function that converts CompletionRequest to the Anthropic API JSON body. Add:
    - If `request.output_config` is Some, include it in the JSON body as `"output_config": { "format": { "type": "json_schema", "json_schema": { "name": "...", "schema": ..., "strict": ... } } }`.
    - Per research CORRECTION 3: No beta header needed for Opus 4.6, Sonnet 4.5, Haiku 4.5 -- structured output is GA.
    - When output_config is present, force `stream: false` (research pitfall 3: structured output with streaming is not supported for builder use case).

    2. **Bedrock provider** (`crates/boternity-infra/src/llm/bedrock/mod.rs`):
    Same approach -- find the request builder and forward output_config if present. Bedrock uses the same Messages API format. Per research pitfall 10: ensure output_config is forwarded.

    3. Both providers should only serialize the output_config field when it's Some (skip_serializing_if = "Option::is_none" is already on the type, but verify the provider serializers respect it).
  </action>
  <verify>
    `cargo check -p boternity-infra` compiles.
    Existing LLM provider tests still pass: `cargo test -p boternity-infra llm`.
    Add a test that verifies output_config appears in the serialized Anthropic request body when set.
  </verify>
  <done>output_config forwarded through both Anthropic and Bedrock providers. Existing tests unaffected (backward compatible).</done>
</task>

<task type="auto">
  <name>Task 2: LlmBuilderAgent implementation with memory recall</name>
  <files>
    crates/boternity-infra/src/builder/llm_builder.rs
    crates/boternity-infra/src/builder/mod.rs
  </files>
  <action>
    Create `crates/boternity-infra/src/builder/llm_builder.rs`:

    **LlmBuilderAgent** struct holding the provider and an optional memory store:
    ```rust
    pub struct LlmBuilderAgent<M: BuilderMemoryStore> {
        provider: BoxLlmProvider,
        memory_store: Option<M>,
    }
    ```

    The generic `M: BuilderMemoryStore` allows injecting the SQLite memory store from AppState. If memory_store is None, recalled_memories will be empty (no suggestions from past sessions). This keeps the agent functional in tests without a database.

    Implement `BuilderAgent for LlmBuilderAgent<M>`:

    **`start()`:**
    1. Create new BuilderState with session_id and initial_description
    2. Run classify_purpose on initial_description to seed purpose_category
    3. Query builder memory: if memory_store is Some, call `memory_store.recall_by_category(&purpose_category, 3)` to get up to 3 past sessions in the same category. Convert BuilderMemoryEntry results to RecalledBuilderMemory structs.
    4. Build Forge system prompt via `build_forge_system_prompt(&state, BuilderMode::NewBot, &recalled_memories)` -- this passes the recalled sessions so Forge can suggest "Last time you chose X"
    5. Generate JSON schema from BuilderTurn via `schemars::schema_for!(BuilderTurn)`
    6. Post-process schema with `add_additional_properties_false()` (CRITICAL per research FINDING 1)
    7. Create CompletionRequest with:
       - system: Forge system prompt (now includes past session context)
       - messages: [User message: initial_description]
       - output_config: Some(OutputConfig with BuilderTurn schema)
       - stream: false
       - temperature: 0.7
       - max_tokens: 2048
    8. Call provider.complete() (non-streaming)
    9. Parse response.content as BuilderTurn via serde_json::from_str
    10. If parse fails, return BuilderError::ParseError with raw content for debugging
    11. Return the BuilderTurn

    **`next_turn(state, answer)`:**
    1. Handle BuilderAnswer::Back -> call state.go_back(), rebuild prompt, call LLM for new question at the restored phase
    2. For other answers: format answer as string, call state.record_exchange with the previous question and this answer
    3. Update state.config fields based on the answer (match on current phase)
    4. Rebuild Forge system prompt with updated state (recalled_memories stays the same across turns -- query once at start)
    5. Create CompletionRequest with full context (system prompt has conversation_summary)
    6. Messages: just the latest user answer (conversation context is in system prompt)
    7. Call provider.complete(), parse BuilderTurn
    8. If BuilderTurn is AskQuestion with a different phase, call state.advance_phase
    9. Return BuilderTurn

    **`resume(state)`:**
    1. Rebuild Forge system prompt from saved state
    2. Query memory again for recalled_memories (same category)
    3. Add instruction: "The user is resuming a previous builder session. Their progress so far is in the accumulated context. Continue from where they left off."
    4. Call LLM with system prompt and a user message "I'd like to continue where I left off"
    5. Parse and return BuilderTurn

    **`reconfigure(state, current_config)`:**
    1. Populate state.config from current_config
    2. Build Forge system prompt with BuilderMode::ReconfigureBot
    3. Call LLM with config context
    4. Parse and return BuilderTurn (should be a Clarify asking what to adjust)

    **Internal helper:**
    ```rust
    async fn call_llm(
        &self,
        system_prompt: String,
        user_message: String,
    ) -> Result<BuilderTurn, BuilderError> {
        // Build schema, create request, call provider.complete(), parse JSON
    }

    async fn recall_memories(&self, category: &PurposeCategory) -> Vec<RecalledBuilderMemory> {
        match &self.memory_store {
            Some(store) => {
                store.recall_by_category(category, 3).await
                    .unwrap_or_default()
                    .into_iter()
                    .map(|entry| RecalledBuilderMemory {
                        initial_description: entry.initial_description,
                        chosen_tone: entry.chosen_tone,
                        chosen_model: entry.chosen_model,
                        chosen_skills: entry.chosen_skills,
                        bot_slug: entry.bot_slug,
                    })
                    .collect()
            }
            None => vec![],
        }
    }
    ```

    Store `recalled_memories: Vec<RecalledBuilderMemory>` as a field populated on start/resume and reused across next_turn calls (no re-querying per turn).

    Update `crates/boternity-infra/src/builder/mod.rs` to add `pub mod llm_builder;`.
  </action>
  <verify>
    `cargo check -p boternity-infra` compiles.
    `cargo test --workspace` passes.
    The LlmBuilderAgent is testable with a mock provider -- add a test that:
    - Creates LlmBuilderAgent with a mock BoxLlmProvider that returns a valid BuilderTurn JSON, and memory_store: None
    - Calls start() with "I want a coding assistant"
    - Verifies the returned BuilderTurn is AskQuestion
    This requires a mock provider or a test helper. If mock infrastructure exists from Phase 2/3 tests, reuse it. Otherwise, create a minimal MockLlmProvider that returns a static CompletionResponse.
  </verify>
  <done>LlmBuilderAgent implements BuilderAgent using Claude structured output. Queries builder memory on start/resume and passes recalled sessions to Forge prompt for suggestion-based UX. JSON schema generated from BuilderTurn with additionalProperties: false post-processing. Non-streaming calls for builder turns.</done>
</task>

</tasks>

<verification>
- `cargo check --workspace` compiles
- `cargo test --workspace` passes
- output_config forwarded through both Anthropic and Bedrock providers
- LlmBuilderAgent calls LLM with structured output schema
- LlmBuilderAgent queries memory store and passes recalled sessions to prompt
- BuilderTurn responses parse correctly from JSON
</verification>

<success_criteria>
- Anthropic and Bedrock providers forward output_config when present
- LlmBuilderAgent::start() queries memory, generates first question with past session context
- LlmBuilderAgent::next_turn() advances conversation with accumulated context
- Back navigation works (go_back + re-ask)
- Resume and reconfigure modes work
- Structured output schema includes additionalProperties: false
- Builder memory recall flows: memory_store -> recalled_memories -> build_forge_system_prompt -> LLM sees past sessions
</success_criteria>

<output>
After completion, create `.planning/phases/07-builder-system/07-05-SUMMARY.md`
</output>
