---
phase: 08-workflows-pipelines
plan: 03
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - crates/boternity-core/src/workflow/mod.rs
  - crates/boternity-core/src/workflow/definition.rs
  - crates/boternity-core/src/workflow/context.rs
  - crates/boternity-core/src/workflow/dag.rs
  - crates/boternity-core/src/lib.rs
autonomous: true

must_haves:
  truths:
    - "YAML workflow files can be parsed into WorkflowDefinition and serialized back to valid YAML"
    - "DAG cycle detection catches invalid dependency graphs"
    - "Steps are organized into parallel execution waves by topological sort"
    - "WorkflowContext tracks step outputs and supports template variable resolution"
  artifacts:
    - path: "crates/boternity-core/src/workflow/definition.rs"
      provides: "YAML parsing, validation, filesystem load/save"
      min_lines: 80
    - path: "crates/boternity-core/src/workflow/dag.rs"
      provides: "DAG builder, cycle detection, wave computation"
      min_lines: 100
    - path: "crates/boternity-core/src/workflow/context.rs"
      provides: "WorkflowContext with step output storage and template resolution"
      min_lines: 60
  key_links:
    - from: "crates/boternity-core/src/workflow/dag.rs"
      to: "petgraph::algo::toposort"
      via: "DAG validation and topological ordering"
      pattern: "toposort|petgraph"
    - from: "crates/boternity-core/src/workflow/definition.rs"
      to: "serde_yaml_ng"
      via: "YAML parse/serialize"
      pattern: "serde_yaml_ng"
---

<objective>
Build the workflow definition parser, DAG validator, and execution context model.

Purpose: This is the "brain" of the workflow engine -- it understands workflow structure, validates dependency graphs, and manages data flow between steps.
Output: Workflow core modules in boternity-core that parse YAML, validate DAGs, compute execution waves, and track context.
</objective>

<execution_context>
@/Users/smxaz7/.claude/get-shit-done/workflows/execute-plan.md
@/Users/smxaz7/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-workflows-pipelines/08-RESEARCH.md
@crates/boternity-core/src/lib.rs
@crates/boternity-core/src/skill/resolver.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Workflow definition parser and filesystem operations</name>
  <files>crates/boternity-core/src/workflow/mod.rs, crates/boternity-core/src/workflow/definition.rs, crates/boternity-core/src/lib.rs</files>
  <action>
Create `crates/boternity-core/src/workflow/` module directory.

Create `mod.rs` exporting: `pub mod definition; pub mod dag; pub mod context;`

Create `definition.rs` with:

1. `parse_workflow_yaml(yaml: &str) -> Result<WorkflowDefinition, WorkflowError>` -- parses YAML string into WorkflowDefinition via serde_yaml_ng::from_str. Runs validate_definition() after parsing.

2. `serialize_workflow_yaml(def: &WorkflowDefinition) -> Result<String, WorkflowError>` -- serializes WorkflowDefinition to YAML string via serde_yaml_ng::to_string.

3. `validate_definition(def: &WorkflowDefinition) -> Result<(), WorkflowError>` -- validates:
   - Name is non-empty and contains only alphanumeric + hyphens
   - All step IDs are unique
   - All depends_on references point to existing step IDs
   - No orphan steps referenced in Conditional.then_steps/else_steps or Loop.body_steps
   - At least one step exists
   - Sub-workflow depth cap: 5 (per Claude's discretion)
   - Concurrency >= 1 if set
   - Timeout > 0 if set

4. `load_workflow_file(path: &Path) -> Result<WorkflowDefinition, WorkflowError>` -- reads file, parses YAML.

5. `save_workflow_file(path: &Path, def: &WorkflowDefinition) -> Result<(), WorkflowError>` -- serializes to YAML, writes file. Creates parent dirs if needed.

6. `discover_workflows(base_dir: &Path) -> Result<Vec<(PathBuf, WorkflowDefinition)>, WorkflowError>` -- scans `~/.boternity/workflows/` and `~/.boternity/bots/*/workflows/` for .yaml/.yml files, parses each.

Define `WorkflowError` enum with variants: ParseError(String), ValidationError(String), IoError(std::io::Error), CycleDetected(String), UnknownDependency(String), ExpressionError(String), ExecutionError(String), TimeoutError, ConcurrencyLimitReached, SubWorkflowDepthExceeded { depth: u32, max: u32 }.

Add `pub mod workflow;` to `crates/boternity-core/src/lib.rs`.

Include tests:
- Parse example YAML from research doc (daily-digest workflow)
- Roundtrip: parse -> serialize -> parse produces same structure
- Validation rejects duplicate step IDs
- Validation rejects unknown depends_on references
- Validation rejects empty workflow
  </action>
  <verify>`cargo test -p boternity-core -- workflow::definition` passes</verify>
  <done>Workflow YAML parser, validator, and filesystem operations work correctly</done>
</task>

<task type="auto">
  <name>Task 2: DAG builder with topological sort and workflow context</name>
  <files>crates/boternity-core/src/workflow/dag.rs, crates/boternity-core/src/workflow/context.rs</files>
  <action>
Create `dag.rs` with:

1. `build_execution_plan(steps: &[StepDefinition]) -> Result<Vec<Vec<&StepDefinition>>, WorkflowError>`:
   - Build petgraph::DiGraph<&str, ()> where nodes are step IDs, edges are depends_on -> step
   - Call petgraph::algo::toposort() -- if Err, return CycleDetected
   - Group steps into parallel waves: Wave N contains steps whose latest dependency is in Wave N-1
   - Algorithm: compute depth for each node (max dependency depth + 1), group by depth
   - Return Vec of waves, where each wave is Vec of steps that can run in parallel

2. `validate_dag(steps: &[StepDefinition]) -> Result<(), WorkflowError>`:
   - Builds graph, checks for cycles, checks all depends_on targets exist
   - Lighter than build_execution_plan (no wave computation)

3. `get_step_dependencies(step_id: &str, steps: &[StepDefinition]) -> Vec<&str>`:
   - Returns transitive closure of all dependencies for a given step

Create `context.rs` with:

1. `WorkflowContext` struct:
   - `step_outputs: HashMap<String, serde_json::Value>` (step_id -> output)
   - `variables: HashMap<String, serde_json::Value>` (user-defined variables)
   - `trigger_payload: Option<serde_json::Value>` (trigger context)
   - `workflow_name: String`
   - `run_id: Uuid`

2. Methods:
   - `new(workflow_name: String, run_id: Uuid, trigger_payload: Option<serde_json::Value>) -> Self`
   - `set_step_output(&mut self, step_id: &str, output: serde_json::Value)` -- enforces 1MB limit per output (truncates with warning)
   - `get_step_output(&self, step_id: &str) -> Option<&serde_json::Value>`
   - `resolve_template(&self, template: &str) -> String` -- resolves `{{ steps.step_id.output }}` and `{{ trigger.field }}` patterns. Simple string replacement, not a full template engine.
   - `total_size(&self) -> usize` -- sum of all serialized output sizes
   - `to_json(&self) -> serde_json::Value` -- serializes entire context for checkpoint
   - `from_json(value: serde_json::Value) -> Result<Self, WorkflowError>` -- restores from checkpoint

Constants: `MAX_STEP_OUTPUT_SIZE: usize = 1_048_576` (1MB), `MAX_CONTEXT_SIZE: usize = 10_485_760` (10MB).

Include tests:
- DAG with no dependencies -> single wave with all steps
- Linear chain A->B->C -> three waves
- Diamond A->{B,C}->D -> three waves (A), (B,C), (D)
- Cycle A->B->A -> CycleDetected error
- Template resolution: `{{ steps.gather.output }}` resolves to stored output
- Context size enforcement
  </action>
  <verify>`cargo test -p boternity-core -- workflow::dag workflow::context` passes</verify>
  <done>DAG builder produces correct parallel waves, context tracks outputs with size limits</done>
</task>

</tasks>

<verification>
- `cargo check --workspace` compiles
- YAML parsing roundtrips correctly
- DAG validation catches cycles and missing dependencies
- Topological sort produces correct wave groupings
- WorkflowContext respects 1MB per-step and 10MB total limits
</verification>

<success_criteria>
- YAML workflow definitions parse and validate correctly
- Petgraph-based DAG validation detects cycles
- Steps are grouped into parallel execution waves
- WorkflowContext manages step outputs with template resolution and size limits
</success_criteria>

<output>
After completion, create `.planning/phases/08-workflows-pipelines/08-03-SUMMARY.md`
</output>
