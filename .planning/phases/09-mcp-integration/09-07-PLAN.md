---
phase: 09-mcp-integration
plan: 07
type: execute
wave: 4
depends_on: ["09-04"]
files_modified:
  - crates/boternity-core/src/agent/engine.rs
  - crates/boternity-core/src/agent/prompt.rs
  - crates/boternity-infra/src/mcp/agent_integration.rs
  - crates/boternity-infra/src/mcp/mod.rs
autonomous: true

must_haves:
  truths:
    - "Bot can invoke MCP tools during conversation (tool use loop)"
    - "MCP tools appear alongside native skills in the LLM context"
    - "Tool results are sanitized before entering bot context"
    - "Graceful degradation: bot continues without tools if MCP server disconnects"
    - "Full tool results persisted in chat history"
  artifacts:
    - path: "crates/boternity-infra/src/mcp/agent_integration.rs"
      provides: "MCP tool use integration with agent engine"
      min_lines: 100
      contains: "mcp_tool_use"
    - path: "crates/boternity-core/src/agent/prompt.rs"
      provides: "System prompt with MCP tool descriptions"
      contains: "mcp_tools"
  key_links:
    - from: "crates/boternity-infra/src/mcp/agent_integration.rs"
      to: "crates/boternity-infra/src/mcp/client_manager.rs"
      via: "McpClientManager::call_tool"
      pattern: "call_tool"
    - from: "crates/boternity-core/src/agent/prompt.rs"
      to: "crates/boternity-types/src/mcp.rs"
      via: "McpToolInfo in prompt"
      pattern: "McpToolInfo"
---

<objective>
Integrate MCP tool consumption into the agent engine so bots can invoke external MCP tools during conversation.

Purpose: This bridges MCP client infrastructure (Plan 04) with the existing agent engine. When a bot has MCP servers connected, the available tools are presented to the LLM alongside native skills. When the LLM requests a tool call, the agent engine routes it to the MCP client manager. Results are sanitized and added to the conversation. Per locked decision: tool results are persisted in chat history for context continuity.
Output: Agent engine MCP tool integration and system prompt injection.
</objective>

<execution_context>
@/Users/smxaz7/.claude/get-shit-done/workflows/execute-plan.md
@/Users/smxaz7/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-mcp-integration/09-RESEARCH.md
@crates/boternity-core/src/agent/engine.rs
@crates/boternity-core/src/agent/prompt.rs
@crates/boternity-infra/src/mcp/client_manager.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: System prompt MCP tool injection</name>
  <files>crates/boternity-core/src/agent/prompt.rs</files>
  <action>
Extend the SystemPromptBuilder to include MCP tool descriptions in the system prompt.

Add a method or section builder:
```rust
pub fn build_mcp_tools_section(tools: &[McpToolInfo]) -> String
```

This generates an XML-tagged section (consistent with existing `<soul>`, `<identity>`, etc. sections):
```xml
<available_mcp_tools>
You have access to the following external tools from connected MCP servers:

{for each tool:}
- **{tool.name}** (from {tool.server_name}): {tool.description}
  Input schema: {tool.input_schema as compact JSON}

To use a tool, respond with a tool_use block specifying the tool name and arguments.
</available_mcp_tools>
```

The section is only added when `tools` is non-empty. When empty, no section is added (graceful degradation per locked decision).

Also extend the existing `AgentContext` or create a new field for MCP tools:
- Add `mcp_tools: Vec<McpToolInfo>` to AgentContext (or a new struct that wraps AgentContext)
- The chat handler populates this from the McpClientManager before building the system prompt

Ensure the MCP tools section integrates with the existing token budget system (mcp_tools contribute to the conversation budget).
  </action>
  <verify>`cargo check -p boternity-core` compiles with MCP tool prompt section</verify>
  <done>System prompt includes MCP tool descriptions when available, omits section when no tools connected</done>
</task>

<task type="auto">
  <name>Task 2: Agent engine tool use loop</name>
  <files>crates/boternity-infra/src/mcp/agent_integration.rs, crates/boternity-infra/src/mcp/mod.rs</files>
  <action>
Create `agent_integration.rs` that provides the MCP tool use integration layer.

Add `pub mod agent_integration;` to mcp/mod.rs.

This module provides helper functions for the chat handlers (CLI and HTTP) to wire MCP tools into the conversation loop:

**prepare_mcp_context:**
```rust
pub async fn prepare_mcp_context(
    client_manager: &dyn McpClientManager,
    bot_id: &Uuid,
    permissions: &McpToolPermissions,
) -> Vec<McpToolInfo>
```
Loads available tools for the bot, returns them for prompt injection. Returns empty vec if client_manager has no connections (graceful degradation).

**convert_to_anthropic_tools:**
```rust
pub fn convert_to_anthropic_tools(mcp_tools: &[McpToolInfo]) -> Vec<serde_json::Value>
```
Converts McpToolInfo list to the Anthropic API tool format (or the internal CompletionRequest tool format) so the LLM provider sees them as callable tools. Each tool gets:
- `name`: tool name
- `description`: sanitized description
- `input_schema`: from McpToolInfo

**handle_tool_use:**
```rust
pub async fn handle_tool_use(
    client_manager: &dyn McpClientManager,
    sanitizer: &dyn ToolSanitizer,
    tool_name: &str,
    tool_input: serde_json::Value,
) -> Result<String, anyhow::Error>
```
1. Parse server_name from tool_name (tools are namespaced or we maintain a lookup)
2. Call `client_manager.call_tool(server_name, tool_name, tool_input)`
3. Sanitize the result via `sanitizer.sanitize_tool_result()`
4. Return sanitized result string

**format_tool_result_for_history:**
```rust
pub fn format_tool_result_for_history(
    tool_name: &str,
    input: &serde_json::Value,
    output: &str,
    duration_ms: u64,
) -> String
```
Formats tool call for chat history persistence (per locked decision: "full tool results persisted in chat history"). Produces a structured format that CLI and web UI can render as collapsible blocks.

Note: The actual tool use loop (LLM response -> detect tool_use -> call tool -> append result -> re-send to LLM) happens in the chat handlers. This module provides the building blocks. The Anthropic API already supports tool_use content blocks -- the integration adds MCP tools to the tool definitions sent with each request.

If the existing agent engine already has a tool use mechanism (from skill system), extend it rather than creating a parallel one. Check if CompletionRequest has a `tools` field.
  </action>
  <verify>`cargo check -p boternity-infra` compiles agent integration module</verify>
  <done>Agent integration provides tool context preparation, Anthropic tool format conversion, tool call handling with sanitization, and history formatting</done>
</task>

</tasks>

<verification>
- `cargo check -p boternity-core` passes (prompt builder extended)
- `cargo check -p boternity-infra` passes (agent integration compiles)
- MCP tools appear in system prompt when available
- Tool call results are sanitized before returning to conversation
- Empty tool list produces no prompt section (graceful degradation)
</verification>

<success_criteria>
MCP tools are integrated into the agent conversation loop: available tools from connected MCP servers appear in the LLM context, tool calls are dispatched through the client manager, results are sanitized, and the full tool call is persisted in chat history. Bot continues normally if no MCP servers are connected.
</success_criteria>

<output>
After completion, create `.planning/phases/09-mcp-integration/09-07-SUMMARY.md`
</output>
