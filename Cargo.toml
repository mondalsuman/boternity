[workspace]
resolver = "3"
members = [
    "crates/boternity-types",
    "crates/boternity-core",
    "crates/boternity-infra",
    "crates/boternity-api",
    "crates/boternity-observe",
]

[workspace.package]
version = "0.1.0"
edition = "2024"
license = "MIT"

[workspace.dependencies]
# HTTP framework
axum = { version = "0.8", features = ["macros"] }

# Async runtime
tokio = { version = "1", features = ["full"] }

# Async SQL toolkit (SQLite)
sqlx = { version = "0.8", features = ["runtime-tokio", "sqlite"] }

# CLI argument parsing
clap = { version = "4.5", features = ["derive", "env"] }
clap_complete = "4.5"

# CLI interaction
dialoguer = { version = "0.11", features = ["password"] }
indicatif = "0.17"
comfy-table = "7"
console = "0.15"

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"

# Unique identifiers (UUID v7 time-sortable)
uuid = { version = "1.20", features = ["v7", "serde"] }

# Date/time
chrono = { version = "0.4", features = ["serde"] }

# Structured logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }

# HTTP middleware
tower-http = { version = "0.6", features = ["cors", "trace", "compression-gzip", "fs"] }

# OS keychain integration
keyring = { version = "3.6", features = ["apple-native", "sync-secret-service", "crypto-rust"] }

# Cryptography (RustCrypto ecosystem)
aes-gcm = "0.10"
argon2 = "0.5"
sha2 = "0.10"

# Platform directories
dirs = "6"

# Error handling
thiserror = "1"
anyhow = "1"

# Temporary files
tempfile = "3"

# LLM provider HTTP + streaming
reqwest = { version = "0.12", features = ["json", "stream"] }
reqwest-eventsource = "0.6"
eventsource-stream = "0.2"
async-stream = "0.3"
futures-util = "0.3"

# Terminal rendering
termimad = "0.34"
syntect = { version = "5", default-features = false, features = ["default-fancy"] }

# Async CLI input
rustyline-async = "0.4"

# Crossterm (terminal manipulation)
crossterm = "0.28"

# Secret wrapping for API keys
secrecy = { version = "0.10", features = ["serde"] }

# Pin projection for custom stream types
pin-project-lite = "0.2"

# Base64 encoding/decoding (Bedrock streaming)
base64 = "0.22"

# OpenAI-compatible LLM provider client
async-openai = { version = "0.32", features = ["chat-completion"] }

# Vector database (embedded) for memory embeddings
lancedb = "0.26"

# Local embedding model inference (ONNX runtime)
fastembed = "5"

# Semantic text chunking for file storage indexing
text-splitter = { version = "0.29", features = ["markdown"] }

# Arrow types (MUST match lancedb's transitive dep -- 57.3.0 for lancedb 0.26)
arrow-schema = "57.3"
arrow-array = "57.3"

# OpenTelemetry
opentelemetry = "0.31"
opentelemetry_sdk = "0.31"
opentelemetry-stdout = "0.31"
tracing-opentelemetry = "0.32"

# Workspace crates
boternity-types = { path = "crates/boternity-types" }
boternity-core = { path = "crates/boternity-core" }
boternity-infra = { path = "crates/boternity-infra" }
boternity-api = { path = "crates/boternity-api" }
boternity-observe = { path = "crates/boternity-observe" }
